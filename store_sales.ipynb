{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desafio Store Sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregamento dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação das bibliotecas necessárias à seção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow\n",
    "from datetime import datetime, timedelta\n",
    "import calendar\n",
    "import multiprocessing \n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "np.set_printoptions(suppress=True, precision=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação dos datasets CSV e ajuste dos tipos das variáveis (histórico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apenas registro histórico, caso seja necessário recuperar os arquivos do início\n",
    "\"\"\"\n",
    "treino = pd.read_csv(\"./csv/train.csv\")\n",
    "treino[\"date\"] = pd.to_datetime(treino[\"date\"])\n",
    "\n",
    "teste = pd.read_csv(\"./csv/test.csv\")\n",
    "teste[\"date\"] = pd.to_datetime(teste[\"date\"])\n",
    "\n",
    "feriados = pd.read_csv(\"./csv/holidays_events.csv\")\n",
    "feriados[\"date\"] = pd.to_datetime(feriados[\"date\"])\n",
    "\n",
    "gasolina = pd.read_csv(\"./csv/oil.csv\")\n",
    "gasolina[\"date\"] = pd.to_datetime(gasolina[\"date\"])\n",
    "\n",
    "transacoes = pd.read_csv(\"./csv/transactions.csv\")\n",
    "transacoes[\"date\"] = pd.to_datetime(transacoes[\"date\"])\n",
    "\n",
    "lojas = pd.read_csv(\"s./csv/tores.csv\") # não tem data envolvida. Dropa city/state?\n",
    "\n",
    "# Transformação das demais variáveis categóricas efetivamente em categorias\n",
    "treino[\"store_nbr\"] = treino[\"store_nbr\"].astype(\"category\")\n",
    "treino[\"family\"] = treino[\"family\"].astype(\"category\")\n",
    "\n",
    "teste[\"store_nbr\"] = teste[\"store_nbr\"].astype(\"category\")\n",
    "teste[\"family\"] = teste[\"family\"].astype(\"category\")\n",
    "\n",
    "feriados[\"type\"] = feriados[\"type\"].astype(\"category\")\n",
    "feriados[\"locale\"] = feriados[\"locale\"].astype(\"category\")\n",
    "feriados[\"locale_name\"] = feriados[\"locale_name\"].astype(\"category\")\n",
    "feriados[\"transferred\"] = feriados[\"transferred\"].astype(\"category\")\n",
    "feriados = feriados[feriados[\"transferred\"] == False]\n",
    "feriados.drop(feriados[feriados[\"date\"] < \"2013-01-01\"].index, axis = 0, inplace = True)\n",
    "feriados.drop(feriados[feriados[\"date\"] >= \"2017-09-01\"].index, axis = 0, inplace = True)\n",
    "feriados.reset_index(inplace = True)\n",
    "feriados.drop(\"index\", axis = 1, inplace = True)\n",
    "feriados[\"f_nacional\"] = 0\n",
    "feriados[\"f_regional\"] = 0\n",
    "feriados[\"f_local\"] = 0\n",
    "    # Cria as dummies\n",
    "for i in range(len(feriados)):\n",
    "    if feriados.loc[i, \"locale\"] == \"National\":\n",
    "        feriados.loc[i, \"f_nacional\"] = 1\n",
    "    elif feriados.loc[i, \"locale\"] == \"Regional\":\n",
    "        feriados.loc[i, \"f_regional\"] = 1\n",
    "    elif feriados.loc[i, \"locale\"] == \"Local\":\n",
    "        feriados.loc[i, \"f_local\"] = 1\n",
    "\n",
    "\n",
    "gasolina.fillna(method='bfill', inplace=True)\n",
    "\n",
    "transacoes[\"store_nbr\"] = transacoes[\"store_nbr\"].astype(\"category\")\n",
    "\n",
    "lojas[\"store_nbr\"] = lojas[\"store_nbr\"].astype(\"category\")\n",
    "lojas[\"type\"] = lojas[\"type\"].astype(\"category\")\n",
    "lojas[\"cluster\"] = lojas[\"cluster\"].astype(\"category\")\n",
    "\n",
    "# Exportação para parquet dos dados já brevemente ajustados \n",
    "\n",
    "teste.to_parquet(\"./parquet/teste.parquet\")\n",
    "treino.to_parquet(\"./parquet/treino.parquet\")\n",
    "feriados.to_parquet(\"./parquet/feriados.parquet\")\n",
    "gasolina.to_parquet(\"./parquet/gasolina.parquet\")\n",
    "transacoes.to_parquet(\"./parquet/transacoes.parquet\")\n",
    "lojas.to_parquet(\"./parquet/lojas.parquet\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engeneering parcial (histórico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apenas registro histórico, caso seja necessário recuperar os arquivos do início\n",
    "\"\"\"\n",
    "###\n",
    "# Dataset de treino\n",
    "### \n",
    "\n",
    "# store_type\n",
    "for i in range(len(treino[\"store_type\"])):\n",
    "    treino[\"store_type\"].iloc[i] = lojas[\"type\"][treino[\"store_nbr\"].iloc[i] == lojas[\"store_nbr\"]].values[0]\n",
    "\n",
    "# cluster\n",
    "for i in range(len(treino[\"cluster\"])):\n",
    "    treino[\"cluster\"].iloc[i] = lojas[\"cluster\"][treino[\"store_nbr\"].iloc[i] == lojas[\"store_nbr\"]].values[0]\n",
    "\n",
    "    \n",
    "# holidays_events\n",
    "treino[\"f_nacional\"] = 0\n",
    "treino[\"f_regional\"] = 0\n",
    "treino[\"f_local\"] = 0\n",
    "for i in range(len(feriados)):\n",
    "    if feriados.loc[i, \"f_nacional\"] == 1:\n",
    "        mask = treino[\"date\"] == feriados.loc[i, \"date\"]\n",
    "        treino.loc[mask, \"f_nacional\"] = 1\n",
    "    elif feriados.loc[i, \"f_regional\"] == 1:\n",
    "        mask = treino[\"date\"] == feriados.loc[i, \"date\"]\n",
    "        treino.loc[mask, \"f_regional\"] = 1\n",
    "    elif feriados.loc[i, \"f_local\"] == 1:\n",
    "        mask = treino[\"date\"] == feriados.loc[i, \"date\"]\n",
    "        treino.loc[mask, \"f_local\"] = 1\n",
    "treino[\"f_nacional\"] = treino[\"f_nacional\"].astype(\"category\")\n",
    "treino[\"f_regional\"] = treino[\"f_regional\"].astype(\"category\")\n",
    "treino[\"f_local\"] = treino[\"f_local\"].astype(\"category\")\n",
    "\n",
    "\n",
    "# oil\n",
    "for i in range(len(gasolina[\"date\"])):\n",
    "    mask = gasolina[\"date\"].iloc[i] == treino[\"date\"]\n",
    "    treino[\"gasolina\"][mask] = gasolina[\"dcoilwtico\"].loc[i]\n",
    "\n",
    "mask = treino[\"gasolina\"] == 0\n",
    "treino.loc[mask, \"gasolina\"] = np.nan\n",
    "treino[\"gasolina\"].fillna(method='bfill', inplace=True)\n",
    "\n",
    "# transactions\n",
    "for date in transacoes[\"date\"].unique():\n",
    "    mask = transacoes[transacoes[\"date\"] == date]\n",
    "    for i in mask[\"store_nbr\"]:\n",
    "        if mask.loc[(mask[\"store_nbr\"] == i), \"transactions\"].values[0] == 0: pass\n",
    "        else:\n",
    "            mask_venda = treino[(treino[\"date\"] == date) & (treino[\"store_nbr\"] == i)]\n",
    "            vendas = mask_venda[\"sales\"].sum()\n",
    "            trans_loja = mask[mask[\"store_nbr\"] == i][\"transactions\"]\n",
    "            ticket_medio = vendas/trans_loja.values[0]\n",
    "            filtro = treino[(treino[\"date\"] == date) & (treino[\"store_nbr\"] == i) & (treino[\"sales\"] > 0)].index\n",
    "            treino.loc[filtro, \"ticket_medio\"] = ticket_medio\n",
    "\n",
    "# fim_de_semana (dummy)\n",
    "for i in treino[\"date\"].index:\n",
    "    if (treino[\"date\"][i].strftime('%A') == \"Saturday\") | (treino[\"date\"][i].strftime('%A') == \"Sunday\"): treino.loc[i, \"fim_de_semana\"] = 1 \n",
    "    else: pass\n",
    "\n",
    "# pgto (indicador ordinal regressivo discreto do dia de pagamento no dia 15)\n",
    "for i in treino.index:\n",
    "        # dia 15\n",
    "    if treino.loc[i, \"date\"].strftime(\"%d\") != \"15\": pass\n",
    "    else: treino.loc[i, \"pgto\"] = 6\n",
    "        # dia 16\n",
    "    if treino.loc[i, \"date\"].strftime(\"%d\") != \"16\": pass\n",
    "    else: treino.loc[i, \"pgto\"] = 5\n",
    "        # dia 17\n",
    "    if treino.loc[i, \"date\"].strftime(\"%d\") != \"17\": pass\n",
    "    else: treino.loc[i, \"pgto\"] = 4\n",
    "        # dia 18\n",
    "    if treino.loc[i, \"date\"].strftime(\"%d\") != \"18\": pass\n",
    "    else: treino.loc[i, \"pgto\"] = 3\n",
    "        # dia 19\n",
    "    if treino.loc[i, \"date\"].strftime(\"%d\") != \"19\": pass\n",
    "    else: treino.loc[i, \"pgto\"] = 2\n",
    "        # dia 20\n",
    "    if treino.loc[i, \"date\"].strftime(\"%d\") != \"20\": pass\n",
    "    else: treino.loc[i, \"pgto\"] = 1\n",
    "\n",
    "# pgto (indicador ordinal regressivo discreto do dia de pagamento no último dia do mês)\n",
    "for i in treino.index:\n",
    "    ultimo_dia = calendar.monthrange(treino.loc[i, \"date\"].year, treino.loc[i, \"date\"].month)[1]\n",
    "        # ultimo dia do mês em curso\n",
    "    if treino.loc[i, \"date\"].strftime(\"%d\") != str(ultimo_dia): pass\n",
    "    else: treino.loc[i, \"pgto\"] = 6\n",
    "        # primeiro dia do mês em curso\n",
    "    if treino.loc[i, \"date\"].strftime(\"%d\") != \"01\": pass\n",
    "    else: treino.loc[i, \"pgto\"] = 5\n",
    "        # dia 02\n",
    "    if treino.loc[i, \"date\"].strftime(\"%d\") != \"02\": pass\n",
    "    else: treino.loc[i, \"pgto\"] = 4\n",
    "        # dia 03\n",
    "    if treino.loc[i, \"date\"].strftime(\"%d\") != \"03\": pass\n",
    "    else: treino.loc[i, \"pgto\"] = 3\n",
    "        # dia 04\n",
    "    if treino.loc[i, \"date\"].strftime(\"%d\") != \"04\": pass\n",
    "    else: treino.loc[i, \"pgto\"] = 2\n",
    "        # dia 05\n",
    "    if treino.loc[i, \"date\"].strftime(\"%d\") != \"05\": pass\n",
    "    else: treino.loc[i, \"pgto\"] = 1\n",
    "\n",
    "# Dados de Seasonality\n",
    "dia_da_semana = treino[\"date\"].dt.dayofweek.copy()\n",
    "mes_do_ano = treino[\"date\"].dt.month.copy()\n",
    "#trimestre = treino[\"date\"].dt.quarter.copy()\n",
    "treino[\"dia_da_semana\"] = dia_da_semana\n",
    "treino[\"mes_do_ano\"] = mes_do_ano\n",
    "treino[\"trimestre\"] = trimestre\n",
    "\n",
    "    \n",
    "###\n",
    "# Dataset de teste\n",
    "### \n",
    "\n",
    "# store_type\n",
    "for i in range(len(teste[\"store_type\"])):\n",
    "    teste[\"store_type\"].iloc[i] = lojas[\"type\"][teste[\"store_nbr\"].iloc[i] == lojas[\"store_nbr\"]].values[0]\n",
    "\n",
    "# cluster\n",
    "for i in range(len(teste[\"cluster\"])):\n",
    "    teste[\"cluster\"].iloc[i] = lojas[\"cluster\"][teste[\"store_nbr\"].iloc[i] == lojas[\"store_nbr\"]].values[0]\n",
    "\n",
    "    \n",
    "# holidays_events\n",
    "teste[\"f_nacional\"] = 0\n",
    "teste[\"f_regional\"] = 0\n",
    "teste[\"f_local\"] = 0\n",
    "for i in range(len(feriados)):\n",
    "    if feriados.loc[i, \"f_nacional\"] == 1:\n",
    "        mask = teste[\"date\"] == feriados.loc[i, \"date\"]\n",
    "        teste.loc[mask, \"f_nacional\"] = 1\n",
    "    elif feriados.loc[i, \"f_regional\"] == 1:\n",
    "        mask = teste[\"date\"] == feriados.loc[i, \"date\"]\n",
    "        teste.loc[mask, \"f_regional\"] = 1\n",
    "    elif feriados.loc[i, \"f_local\"] == 1:\n",
    "        mask = teste[\"date\"] == feriados.loc[i, \"date\"]\n",
    "        teste.loc[mask, \"f_local\"] = 1\n",
    "teste[\"f_nacional\"] = teste[\"f_nacional\"].astype(\"category\")\n",
    "teste[\"f_regional\"] = teste[\"f_regional\"].astype(\"category\")\n",
    "teste[\"f_local\"] = teste[\"f_local\"].astype(\"category\")\n",
    "\n",
    "\n",
    "# oil\n",
    "for i in range(len(gasolina[\"date\"])):\n",
    "    mask = gasolina[\"date\"].iloc[i] == teste[\"date\"]\n",
    "    teste[\"gasolina\"][mask] = gasolina[\"dcoilwtico\"].loc[i]\n",
    "\n",
    "mask = teste[\"gasolina\"] == 0\n",
    "teste.loc[mask, \"gasolina\"] = np.nan\n",
    "teste[\"gasolina\"].fillna(method='bfill', inplace=True)\n",
    "\n",
    "# fim_de_semana (dummy)\n",
    "for i in teste[\"date\"].index:\n",
    "    if (teste[\"date\"][i].strftime('%A') == \"Saturday\") | (teste[\"date\"][i].strftime('%A') == \"Sunday\"): teste.loc[i, \"fim_de_semana\"] = 1 \n",
    "    else: pass\n",
    "\n",
    "# pgto (indicador ordinal regressivo discreto do dia de pagamento)\n",
    "for i in teste.index:\n",
    "        # dia 15\n",
    "    if teste.loc[i, \"date\"].strftime(\"%d\") != \"15\": pass\n",
    "    else: teste.loc[i, \"pgto\"] = 6\n",
    "        # dia 16\n",
    "    if teste.loc[i, \"date\"].strftime(\"%d\") != \"16\": pass\n",
    "    else: teste.loc[i, \"pgto\"] = 5\n",
    "        # dia 17\n",
    "    if teste.loc[i, \"date\"].strftime(\"%d\") != \"17\": pass\n",
    "    else: teste.loc[i, \"pgto\"] = 4\n",
    "        # dia 18\n",
    "    if teste.loc[i, \"date\"].strftime(\"%d\") != \"18\": pass\n",
    "    else: teste.loc[i, \"pgto\"] = 3\n",
    "        # dia 19\n",
    "    if teste.loc[i, \"date\"].strftime(\"%d\") != \"19\": pass\n",
    "    else: teste.loc[i, \"pgto\"] = 2\n",
    "        # dia 20\n",
    "    if teste.loc[i, \"date\"].strftime(\"%d\") != \"20\": pass\n",
    "    else: teste.loc[i, \"pgto\"] = 1\n",
    "\n",
    "\n",
    "# Dados de Seasonality\n",
    "dia_da_semana = teste[\"date\"].dt.dayofweek.copy()\n",
    "mes_do_ano = teste[\"date\"].dt.month.copy()\n",
    "trimestre = teste[\"date\"].dt.quarter.copy()\n",
    "teste[\"dia_da_semana\"] = dia_da_semana\n",
    "teste[\"mes_do_ano\"] = mes_do_ano\n",
    "teste[\"trimestre\"] = trimestre\n",
    "\n",
    "###\n",
    "# Limpeza do workspace\n",
    "### \n",
    "del (mask, feriado, filtro, ticket_medio, trans_loja, vendas, mask_venda, copia, data_teste, date, i, j, dia_da_semana, mes_do_ano, trimestre)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação dos dados (parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados com outliers\n",
    "treino = pd.read_parquet(\"./parquet/treino.parquet\")\n",
    "teste = pd.read_parquet(\"./parquet/teste.parquet\")\n",
    "#feriados = pd.read_parquet(\"./parquet/feriados.parquet\") # mantidos para caso seja necessário importara cada um individualmente\n",
    "#gasolina = pd.read_parquet(\"./parquet/gasolina.parquet\")\n",
    "#transacoes = pd.read_parquet(\"./parquet/transacoes.parquet\")\n",
    "#lojas = pd.read_parquet(\"./parquet/lojas.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gráficos, Outliers e Normalização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibliotecas e funções necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit # separação de grupo treino e teste\n",
    "from sklearn.metrics import root_mean_squared_log_error\n",
    "import xgboost as xgb # https://xgboost.readthedocs.io/en/stable/parameter.html\n",
    "\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definição das funções necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(predt: np.ndarray, dtrain: xgb.DMatrix) -> np.ndarray:\n",
    "    '''Computa o gradient squared log error.'''\n",
    "    y = xgb.DMatrix(dtrain).get_label()\n",
    "    return (np.log1p(predt) - np.log1p(y)) / (predt + 1)\n",
    "\n",
    "def hessian(predt: np.ndarray, dtrain: xgb.DMatrix) -> np.ndarray:\n",
    "    '''Computa o hessiano para o squared log error.'''\n",
    "    y = dtrain.get_label()\n",
    "    return ((-np.log1p(predt) + np.log1p(y) + 1) /\n",
    "            np.power(predt + 1, 2))\n",
    "\n",
    "def squared_log(predt: np.ndarray,\n",
    "                dtrain: xgb.DMatrix) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    '''Squared Log Error. Versão mais simples da RMSLE usada como função objetiva'''\n",
    "    predt[predt < -1] = -1 + 1e-6\n",
    "    grad = gradient(predt, dtrain)\n",
    "    hess = hessian(predt, dtrain)\n",
    "    return grad, hess\n",
    "\n",
    "def rmsle(predt: np.ndarray, dtrain: xgb.DMatrix) -> Tuple[str, float]:\n",
    "    ''' Métrica RMSLE '''\n",
    "    y = dtrain.get_label()\n",
    "    predt[predt < -1] = -1 + 1e-6\n",
    "    elements = np.power(np.log1p(y) - np.log1p(predt), 2)\n",
    "    return 'PyRMSLE', float(np.sqrt(np.sum(elements) / len(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz de Correlação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percebe-se uma alta correlação positiva entre as variáveis 'trimestre' e 'mes_do_ano', optando-se por desconsiderar-se, então, a variável 'trimestre'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essa matriz utiliza o objeto gerado na seção \"União Treino/Teste para criação das variáveis temporais\".\n",
    "\"\"\"\n",
    "#df = treino.drop([\"date\", \"family\", \"store_nbr\", \"cluster\", \"store_type\", \"id\"], axis = 1).copy()\n",
    "df = temp_18m.drop([\"family\", \"store_nbr\", \"cluster\", \"store_type\", \"id\"], axis = 1).copy()\n",
    "corr = df.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "color_pal = sns.color_palette()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualização das variáveis \"gasolina\" (treino/teste) e \"sales\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        \"sales\" e \"gasolina\"\n",
    "\n",
    "A primeira variável ajustada somente no banco de dados de treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "treino.plot(x = \"date\",\n",
    "            y = \"gasolina\",\n",
    "            ylabel = \"Custo monetário\",\n",
    "            xlabel = \"\",\n",
    "            label = \"Custo da gasolina\",\n",
    "            figsize = (15,5),\n",
    "            color = color_pal[0],\n",
    "            title = \"Gráfico 01 - Valor da gasolina ao longo do tempo\\nDataset Treino\")\n",
    "\n",
    "teste.plot(x = \"date\",\n",
    "            y = \"gasolina\",\n",
    "            ylabel = \"Custo monetário\",\n",
    "            xlabel = \"\",\n",
    "            label = \"Custo da gasolina\",\n",
    "            figsize = (15,5),\n",
    "            color = color_pal[0],\n",
    "            title = \"Gráfico 02 - Valor da gasolina ao longo do tempo\\nDataset Teste\")\n",
    "\n",
    "treino.plot(x = \"date\",\n",
    "            y = \"sales\",\n",
    "            ylabel = \"Valor de vendas\",\n",
    "            xlabel = \"\",\n",
    "            label = \"Valor em vendas na data\",\n",
    "            style = '.',\n",
    "            figsize = (15,5),\n",
    "            color = color_pal[1],\n",
    "            title = \"Gráfico 03 - Vendas ao longo do tempo\")\n",
    "\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualização das vendas por loja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "treino[treino[\"date\"] >= \"2017-04-01\"].plot(x = \"date\",\n",
    "            y = \"sales\",\n",
    "            ylabel = \"Valor de vendas\",\n",
    "            xlabel = \"\",\n",
    "            label = \"Valor em vendas na data\",\n",
    "            style = '.',\n",
    "            figsize = (15,5),\n",
    "            color = color_pal[1],\n",
    "            title = \"Gráfico 03 - Vendas ao longo do tempo\")\n",
    "\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualização detalhada da variável \"onpromotion\" (treino/teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na variável \"onpromotion\" eu realizo a análise dos outliers em momentos distintos e claramente identificáveis através dos gráficos.\n",
    "\n",
    "Períodos de separação para análise dos outliers:\n",
    "- desde o início dos registros até 31/03/2014 (onde 'onpromotion' é igual a zero sempre);\n",
    "- de 01/04/2014 até o final desse ano (nada gritante em termos de outliers, apenas promoções sazonais);\n",
    "- 2015 possui o primeiro semestre com menor quantidade de promoções em relação ao segundo semestre, mas mesmo assim sem outliers;\n",
    "- 2016 é o ano do terremoto, onde sim fica gritante a presença de outliers;\n",
    "- 2017 apresenta basicamente promoções regulares e sazonais, mas alguns outliers são identificados e também serão removidos.\n",
    "- dataset de teste também apresenta visualmente alguns outliers no final do período, marcados para remoção."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nteste.plot(x = \"date\",\\n            y = \"onpromotion\",\\n            ylabel = \"Qtde de promoções\",\\n            xlabel = \"\",\\n            label = \"Promoções\",\\n            style = \\'.\\',\\n            figsize = (15,5),\\n            color = color_pal[9],\\n            title = \"Gráfico 04 - Promoções durante todo o período das observações\\nDataset Teste\")\\n\\ntreino.plot(x = \"date\",\\n            y = \"onpromotion\",\\n            ylabel = \"Qtde de promoções\",\\n            xlabel = \"\",\\n            label = \"Promoções\",\\n            style = \\'.\\',\\n            figsize = (15,5),\\n            color = color_pal[2],\\n            title = \"Gráfico 05 - Promoções durante todo o período das observações\\nDataset Treino\")\\n\\ntreino[treino[\"date\"] < \"2014-04-01\"].plot(x = \"date\",\\n            y = \"onpromotion\",\\n            ylabel = \"Qtde de promoções\",\\n            xlabel = \"\",\\n            label = \"Promoções\",\\n            style = \\'.\\',\\n            figsize = (15,5),\\n            color = color_pal[4],\\n            title = \"Gráfico 06 - Promoções do início das observações\\naté 31/03/2014 (inclusive)\")\\n\\ntreino[(treino[\"date\"] >= \"2014-04-01\") & (treino[\"date\"] <= \"2014-12-31\")].plot(x = \"date\",\\n            y = \"onpromotion\",\\n            ylabel = \"Qtde de promoções\",\\n            xlabel = \"\",\\n            label = \"Promoções\",\\n            style = \\'.\\',\\n            figsize = (15,5),\\n            color = color_pal[4],\\n            title = \"Gráfico 07 - Promoções de 2014 a partir de 01/04\")\\n\\ntreino[(treino[\"date\"] >= \"2015-01-01\") & (treino[\"date\"] <= \"2015-12-31\")].plot(x = \"date\",\\n            y = \"onpromotion\",\\n            ylabel = \"Qtde de promoções\",\\n            xlabel = \"\",\\n            label = \"Promoções\",\\n            style = \\'.\\',\\n            figsize = (15,5),\\n            color = color_pal[5],\\n            title = \"Gráfico 08 - Promoções ao longo de todo 2015\")\\n\\ntreino[(treino[\"date\"] >= \"2016-01-01\") & (treino[\"date\"] <= \"2016-12-31\")].plot(x = \"date\",\\n            y = \"onpromotion\",\\n            ylabel = \"Qtde de promoções\",\\n            xlabel = \"\",\\n            label = \"Promoções\",\\n            style = \\'.\\',\\n            figsize = (15,5),\\n            color = color_pal[7],\\n            title = \"Gráfico 09 - Promoções ao longo de todo 2016\")\\n\\ntreino[(treino[\"date\"] >= \"2016-04-16\") & (treino[\"date\"] <= \"2016-06-15\")].plot(x = \"date\",\\n            y = \"onpromotion\",\\n            ylabel = \"Qtde de promoções\",\\n            xlabel = \"\",\\n            label = \"Promoções\",\\n            style = \\'.\\',\\n            figsize = (15,5),\\n            color = color_pal[7],\\n            title = \"Gráfico 10 - Visualização amplidada do período\\nde 16/04/2016 a 15/06/2016 (época do terremoto)\")\\n\\ntreino[treino[\"date\"] >= \"2017-01-01\"].plot(x = \"date\",\\n            y = \"onpromotion\",\\n            ylabel = \"Qtde de promoções\",\\n            xlabel = \"\",\\n            label = \"Promoções\",\\n            style = \\'.\\',\\n            figsize = (15,5),\\n            color = color_pal[8],\\n            title = \"Gráfico 11 - Promoções ao longo de todo 2017 observado\")\\n\\nplt.show()\\n'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "teste.plot(x = \"date\",\n",
    "            y = \"onpromotion\",\n",
    "            ylabel = \"Qtde de promoções\",\n",
    "            xlabel = \"\",\n",
    "            label = \"Promoções\",\n",
    "            style = '.',\n",
    "            figsize = (15,5),\n",
    "            color = color_pal[9],\n",
    "            title = \"Gráfico 04 - Promoções durante todo o período das observações\\nDataset Teste\")\n",
    "\n",
    "treino.plot(x = \"date\",\n",
    "            y = \"onpromotion\",\n",
    "            ylabel = \"Qtde de promoções\",\n",
    "            xlabel = \"\",\n",
    "            label = \"Promoções\",\n",
    "            style = '.',\n",
    "            figsize = (15,5),\n",
    "            color = color_pal[2],\n",
    "            title = \"Gráfico 05 - Promoções durante todo o período das observações\\nDataset Treino\")\n",
    "\n",
    "treino[treino[\"date\"] < \"2014-04-01\"].plot(x = \"date\",\n",
    "            y = \"onpromotion\",\n",
    "            ylabel = \"Qtde de promoções\",\n",
    "            xlabel = \"\",\n",
    "            label = \"Promoções\",\n",
    "            style = '.',\n",
    "            figsize = (15,5),\n",
    "            color = color_pal[4],\n",
    "            title = \"Gráfico 06 - Promoções do início das observações\\naté 31/03/2014 (inclusive)\")\n",
    "\n",
    "treino[(treino[\"date\"] >= \"2014-04-01\") & (treino[\"date\"] <= \"2014-12-31\")].plot(x = \"date\",\n",
    "            y = \"onpromotion\",\n",
    "            ylabel = \"Qtde de promoções\",\n",
    "            xlabel = \"\",\n",
    "            label = \"Promoções\",\n",
    "            style = '.',\n",
    "            figsize = (15,5),\n",
    "            color = color_pal[4],\n",
    "            title = \"Gráfico 07 - Promoções de 2014 a partir de 01/04\")\n",
    "\n",
    "treino[(treino[\"date\"] >= \"2015-01-01\") & (treino[\"date\"] <= \"2015-12-31\")].plot(x = \"date\",\n",
    "            y = \"onpromotion\",\n",
    "            ylabel = \"Qtde de promoções\",\n",
    "            xlabel = \"\",\n",
    "            label = \"Promoções\",\n",
    "            style = '.',\n",
    "            figsize = (15,5),\n",
    "            color = color_pal[5],\n",
    "            title = \"Gráfico 08 - Promoções ao longo de todo 2015\")\n",
    "\n",
    "treino[(treino[\"date\"] >= \"2016-01-01\") & (treino[\"date\"] <= \"2016-12-31\")].plot(x = \"date\",\n",
    "            y = \"onpromotion\",\n",
    "            ylabel = \"Qtde de promoções\",\n",
    "            xlabel = \"\",\n",
    "            label = \"Promoções\",\n",
    "            style = '.',\n",
    "            figsize = (15,5),\n",
    "            color = color_pal[7],\n",
    "            title = \"Gráfico 09 - Promoções ao longo de todo 2016\")\n",
    "\n",
    "treino[(treino[\"date\"] >= \"2016-04-16\") & (treino[\"date\"] <= \"2016-06-15\")].plot(x = \"date\",\n",
    "            y = \"onpromotion\",\n",
    "            ylabel = \"Qtde de promoções\",\n",
    "            xlabel = \"\",\n",
    "            label = \"Promoções\",\n",
    "            style = '.',\n",
    "            figsize = (15,5),\n",
    "            color = color_pal[7],\n",
    "            title = \"Gráfico 10 - Visualização amplidada do período\\nde 16/04/2016 a 15/06/2016 (época do terremoto)\")\n",
    "\n",
    "treino[treino[\"date\"] >= \"2017-01-01\"].plot(x = \"date\",\n",
    "            y = \"onpromotion\",\n",
    "            ylabel = \"Qtde de promoções\",\n",
    "            xlabel = \"\",\n",
    "            label = \"Promoções\",\n",
    "            style = '.',\n",
    "            figsize = (15,5),\n",
    "            color = color_pal[8],\n",
    "            title = \"Gráfico 11 - Promoções ao longo de todo 2017 observado\")\n",
    "\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nterremoto_df = treino[(treino[\"date\"] >= \"2016-04-16\") & (treino[\"date\"] <= \"2016-06-08\")].copy()\\nterremoto_df.plot(x = \"date\",\\n            y = \"onpromotion\",\\n            ylabel = \"Qtde de promoções\",\\n            xlabel = \"\",\\n            label = \"Promoções\",\\n            style = \\'.\\',\\n            figsize = (15,5),\\n            color = color_pal[8],\\n            title = \"Réplica do Gráfico 10:\\nPromoções ao longo do período do terremoto\")\\n\\nplt.show()\\n'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "terremoto_df = treino[(treino[\"date\"] >= \"2016-04-16\") & (treino[\"date\"] <= \"2016-06-08\")].copy()\n",
    "terremoto_df.plot(x = \"date\",\n",
    "            y = \"onpromotion\",\n",
    "            ylabel = \"Qtde de promoções\",\n",
    "            xlabel = \"\",\n",
    "            label = \"Promoções\",\n",
    "            style = '.',\n",
    "            figsize = (15,5),\n",
    "            color = color_pal[8],\n",
    "            title = \"Réplica do Gráfico 10:\\nPromoções ao longo do período do terremoto\")\n",
    "\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tratamento dos outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n \\ntreino[(treino[\"date\"] >= \"2016-04-16\") & (treino[\"date\"] <= \"2016-06-15\")].plot(x = \"date\",\\n            y = \"onpromotion\",\\n            ylabel = \"Qtde de promoções\",\\n            xlabel = \"\",\\n            label = \"Promoções\",\\n            style = \\'.\\',\\n            figsize = (15,5),\\n            color = color_pal[7],\\n            title = \"Gráfico 10 (revisitado) - Visualização amplidada\\ndo período de 16/04/2016 a 15/06/2016 (época do terremoto)\")\\n\\ntreino[treino[\"date\"] >= \"2017-01-01\"].plot(x = \"date\",\\n            y = \"onpromotion\",\\n            ylabel = \"Qtde de promoções\",\\n            xlabel = \"\",\\n            label = \"Promoções\",\\n            style = \\'.\\',\\n            figsize = (15,5),\\n            color = color_pal[7],\\n            title = \"Gráfico 11 (revisitado) - Promoções ao longo de todo 2017 observado\")\\n\\nteste.plot(x = \"date\",\\n            y = \"onpromotion\",\\n            ylabel = \"Qtde de promoções\",\\n            xlabel = \"\",\\n            label = \"Promoções\",\\n            style = \\'.\\',\\n            figsize = (15,5),\\n            color = color_pal[9],\\n            title = \"Gráfico 04 (revisitado) - Promoções durante todo o período das observações\\nDataset Teste\")\\n\\ntreino.plot(x = \"date\",\\n            y = \"sales\",\\n            ylabel = \"Valor de vendas\",\\n            xlabel = \"\",\\n            label = \"Valor em vendas na data\",\\n            style = \\'.\\',\\n            figsize = (15,5),\\n            color = color_pal[1],\\n            title = \"Gráfico 03 (revisitado) - Vendas ao longo do tempo, sem outliers\")\\n\\nplt.show()\\n'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "###\n",
    "# Outliers variável \"onpromotion\" no ano do terremoto (2016)\n",
    "###\n",
    "terremoto_df = treino[(treino[\"date\"] >= \"2016-01-01\") & (treino[\"date\"] <= \"2016-12-31\")].copy()\n",
    "max_terremoto = terremoto_df[terremoto_df[\"date\"] == \"2016-06-08\"][\"onpromotion\"].max() # definida a data de 08/06 com base na dispersão das observações no Gráfico 10\n",
    "apagar = terremoto_df[terremoto_df[\"onpromotion\"] > max_terremoto].index\n",
    "treino = treino.drop(apagar, axis = 0)\n",
    "\n",
    "\n",
    "###\n",
    "# Outliers variável \"onpromotion\" no ano de 2017\n",
    "###\n",
    "ajuste_df = treino[(treino[\"date\"] >= \"2017-01-01\") & (treino[\"date\"] <= \"2017-08-15\")].copy()\n",
    "max_ajuste = ajuste_df[ajuste_df[\"date\"] == \"2017-03-15\"][\"onpromotion\"].max() # definida a data de 15/03, com o máximo de 247\n",
    "apagar = ajuste_df[ajuste_df[\"onpromotion\"] > max_ajuste].index\n",
    "treino = treino.drop(apagar, axis = 0)\n",
    "\n",
    "\n",
    "###\n",
    "# Outliers variável \"sales\"\n",
    "###\n",
    "max_ajuste = treino[treino[\"date\"] == \"2013-02-14\"][\"sales\"].max() # definida a data de 14/02, com o máximo de 26067\n",
    "apagar = treino[treino[\"sales\"] > max_ajuste].index\n",
    "treino = treino.drop(apagar, axis = 0)\n",
    "\"\"\"\n",
    " \n",
    "treino[(treino[\"date\"] >= \"2016-04-16\") & (treino[\"date\"] <= \"2016-06-15\")].plot(x = \"date\",\n",
    "            y = \"onpromotion\",\n",
    "            ylabel = \"Qtde de promoções\",\n",
    "            xlabel = \"\",\n",
    "            label = \"Promoções\",\n",
    "            style = '.',\n",
    "            figsize = (15,5),\n",
    "            color = color_pal[7],\n",
    "            title = \"Gráfico 10 (revisitado) - Visualização amplidada\\ndo período de 16/04/2016 a 15/06/2016 (época do terremoto)\")\n",
    "\n",
    "treino[treino[\"date\"] >= \"2017-01-01\"].plot(x = \"date\",\n",
    "            y = \"onpromotion\",\n",
    "            ylabel = \"Qtde de promoções\",\n",
    "            xlabel = \"\",\n",
    "            label = \"Promoções\",\n",
    "            style = '.',\n",
    "            figsize = (15,5),\n",
    "            color = color_pal[7],\n",
    "            title = \"Gráfico 11 (revisitado) - Promoções ao longo de todo 2017 observado\")\n",
    "\n",
    "teste.plot(x = \"date\",\n",
    "            y = \"onpromotion\",\n",
    "            ylabel = \"Qtde de promoções\",\n",
    "            xlabel = \"\",\n",
    "            label = \"Promoções\",\n",
    "            style = '.',\n",
    "            figsize = (15,5),\n",
    "            color = color_pal[9],\n",
    "            title = \"Gráfico 04 (revisitado) - Promoções durante todo o período das observações\\nDataset Teste\")\n",
    "\n",
    "treino.plot(x = \"date\",\n",
    "            y = \"sales\",\n",
    "            ylabel = \"Valor de vendas\",\n",
    "            xlabel = \"\",\n",
    "            label = \"Valor em vendas na data\",\n",
    "            style = '.',\n",
    "            figsize = (15,5),\n",
    "            color = color_pal[1],\n",
    "            title = \"Gráfico 03 (revisitado) - Vendas ao longo do tempo, sem outliers\")\n",
    "\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normaliza as variáveis _sales_, _onpromotion_ e _gasolina_, depois de concatenar treino e teste. Disponível nos datasets *temp_zscore* e *temp_log*.\n",
    "\n",
    "Ajustar nos datasets para modelagem conforme necessário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler # normalização por z-score\n",
    "from sklearn.preprocessing import FunctionTransformer # normalização por log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_normalizar = [\"sales\", \"onpromotion\", \"gasolina\", \"pgto\"]\n",
    "temp = pd.concat([treino, teste])\n",
    "temp.reset_index(inplace = True, drop = True)\n",
    "temp[\"sales\"] = temp[\"sales\"].fillna(0)\n",
    "temp_norm = temp[a_normalizar].copy()\n",
    "\n",
    "# Normalizaçao por Z-Score\n",
    "zscore_scaler = StandardScaler()\n",
    "temp_zscore = zscore_scaler.fit_transform(temp_norm)\n",
    "temp_zscore = pd.DataFrame(temp_zscore)\n",
    "temp_zscore.columns = temp_norm.columns\n",
    "\n",
    "# Normalização por Log\n",
    "log_scaler = FunctionTransformer(np.log1p)\n",
    "temp_log = log_scaler.fit_transform(temp_norm)\n",
    "\n",
    "temp_snorm = temp.copy()\n",
    "temp.drop(a_normalizar, axis = 1, inplace = True)\n",
    "temp_normz = pd.concat([temp, temp_zscore], axis = 1)\n",
    "temp_norml = pd.concat([temp, temp_log], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelagem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### União treino/teste para criação das variáveis temporais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Descomentar a linha abaixo para utilização de modelagem com valores sem normalização\n",
    "temp = pd.concat([treino, teste])\n",
    "\n",
    "### Descomentar a linha abaixo para utilização de modelagem com valores normalizados via Z-Score\n",
    "#temp = temp_normz.copy()\n",
    "\n",
    "### Descomentar a linha abaixo para utilização de modelagem com valores normalizados via Log\n",
    "#temp = temp_norml.copy()\n",
    "\n",
    "# Criação de objeto das variáveis sem normalização para referência ao comparar os resultados da modelagem na apresentação final\n",
    "temp_snorm = temp.copy()\n",
    "temp[\"sales\"] = temp[\"sales\"].fillna(0)\n",
    "\n",
    "# Criação das variáveis de lag (D-n)\n",
    "temp[\"sales_lag15\"] = temp.groupby([\"family\", \"store_nbr\"], observed = True, as_index = True)[\"sales\"].shift(15)\n",
    "temp[\"sales_lag10\"] = temp.groupby([\"family\", \"store_nbr\"], observed = True, as_index = True)[\"sales\"].shift(10)\n",
    "temp[\"sales_lag5\"] = temp.groupby([\"family\", \"store_nbr\"], observed = True, as_index = True)[\"sales\"].shift(5)\n",
    "temp[\"sales_lag1\"] = temp.groupby([\"family\", \"store_nbr\"], observed = True, as_index = True)[\"sales\"].shift(1)\n",
    "\n",
    "# Criação das variáveis de diferenças\n",
    "temp[\"diff15\"] = temp.groupby([\"family\", \"store_nbr\"], observed = True, as_index = True)[\"sales\"].diff(15)\n",
    "temp[\"diff10\"] = temp.groupby([\"family\", \"store_nbr\"], observed = True, as_index = True)[\"sales\"].diff(10)\n",
    "temp[\"diff5\"] = temp.groupby([\"family\", \"store_nbr\"], observed = True, as_index = True)[\"sales\"].diff(5)\n",
    "temp[\"diff1\"] = temp.groupby([\"family\", \"store_nbr\"], observed = True, as_index = True)[\"sales\"].diff(1)\n",
    "\n",
    "# Apenas registro histórico, se quiser utilizar variável de média móvel - não teve significância em praticamente nenhumm modelo testado\n",
    "#temp[\"mmovel15\"] = temp.groupby([\"family\", \"store_nbr\"], observed = True, as_index = True)[\"sales\"].rolling(15).mean().reset_index(level = 0, drop = True).values\n",
    "\n",
    "\n",
    "# Inclusão de variável conjunta dos feriados nacional, regional e local\n",
    "feriados = pd.read_csv(\"./csv/holidays_events.csv\")\n",
    "feriados[\"date\"] = pd.to_datetime(feriados[\"date\"])\n",
    "for i in range(len(feriados)):\n",
    "    if feriados.loc[i, \"locale\"] == \"National\" or feriados.loc[i, \"locale\"] == \"Regional\" or feriados.loc[i, \"locale\"] == \"Local\":\n",
    "        feriados.loc[i, \"feriado\"] = 1\n",
    "    else: pass\n",
    "\n",
    "temp[\"feriado\"] = 0\n",
    "\n",
    "for i in range(len(feriados)):\n",
    "    if feriados.loc[i, \"feriado\"] == 1:\n",
    "        mask = temp.index == feriados.loc[i, \"date\"]\n",
    "        temp.loc[mask, \"feriado\"] = 1\n",
    "\n",
    "      \n",
    "### Ajuste dos types das variáveis\n",
    "temp[\"store_nbr\"] = temp[\"store_nbr\"].astype(\"category\")\n",
    "temp[\"cluster\"] = temp[\"cluster\"].astype(\"category\")\n",
    "temp[\"pgto\"] = temp[\"pgto\"].astype(\"category\")\n",
    "temp[\"dia_da_semana\"] = temp[\"dia_da_semana\"].astype(\"category\")\n",
    "temp[\"mes_do_ano\"] = temp[\"mes_do_ano\"].astype(\"category\")\n",
    "temp[\"f_nacional\"] = temp[\"f_nacional\"].astype(\"category\")\n",
    "temp[\"f_regional\"] = temp[\"f_regional\"].astype(\"category\")\n",
    "temp[\"f_local\"] = temp[\"f_local\"].astype(\"category\")\n",
    "temp[\"feriado\"] = temp[\"feriado\"].astype(\"category\")\n",
    "\n",
    "\n",
    "# Transformação do índice regular para as datas\n",
    "temp.index = pd.DatetimeIndex(temp[\"date\"])\n",
    "temp.drop([\"date\", \"trimestre\"], axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "# Criação de fatias temporais mais recentes para o estudo, conforme preferência\n",
    "#temp_6m = temp[temp.index > \"2017-02-16\"].copy()\n",
    "#temp_12m = temp[temp.index > \"2016-08-15\"].copy()\n",
    "#temp_18m = temp[temp.index > \"2016-02-16\"].copy()\n",
    "temp_24m = temp[temp.index > \"2015-08-15\"].copy()\n",
    "\n",
    "# Variáveis a remover da modelagem:\n",
    "var_a_remover = [\"id\", \"sales\", \"ticket_medio\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registro à parte das variáveis para remoção por questão de facilidade enquanto se está modelando\n",
    "var_a_remover = [\"id\", \"sales\", \"ticket_medio\", \n",
    "                'gasolina', 'f_local', 'f_regional',\n",
    "                'cluster', 'store_type', 'feriado']\n",
    "\n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usando XGBoost e TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Banco de dados completo\n",
    "#dados_treino = temp[temp[\"id\"] < 3000888].copy()\n",
    "\n",
    "# Banco de dados com os últimos 24 meses apenas\n",
    "dados_treino = temp_24m[temp_24m[\"id\"] < 3000888].copy()\n",
    "\n",
    "# Banco de dados com os últimos 18 meses apenas\n",
    "#dados_treino = temp_18m[temp_18m[\"id\"] < 3000888].copy()\n",
    "\n",
    "# Banco de dados com os últimos 12 meses apenas\n",
    "#dados_treino = temp_12m[temp_12m[\"id\"] < 3000888].copy()\n",
    "\n",
    "# Banco de dados com os últimos 06 meses apenas\n",
    "#dados_treino = temp_6m[temp_6m[\"id\"] < 3000888].copy()\n",
    "\n",
    "# Estabelecimento do nome do modelo para fins de registro\n",
    "nome_modelo = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "\n",
    "# Avisa o tipo de normalização (se existente)\n",
    "if temp[temp.index == \"2017-08-15\"][\"gasolina\"].unique() < 0:\n",
    "    print(\"\\nREALIZANDO MODELAGEM, DADOS COM NORMALIZAÇÃO POR Z-SCORE\\n\")\n",
    "elif temp[temp.index == \"2017-08-15\"][\"gasolina\"].unique() > 5:\n",
    "    print(\"\\nREALIZANDO MODELAGEM, DADOS SEM NORMALIZAÇÃO\\n\")\n",
    "else:\n",
    "    print(\"\\nREALIZANDO MODELAGEM, DADOS COM NORMALIZAÇÃO POR LOG\\n\")\n",
    "\n",
    "# Registra o período dos dados em análise\n",
    "print(\"Período de análise entre\", dados_treino.index.min().strftime(\"%d-%m-%Y\"), \"e\", dados_treino.index.max().strftime(\"%d-%m-%Y\"), \"\\n\")\n",
    "\n",
    "# Informa sobre a existência de outliers no período de análise, tomando por base 'sales' da loja 9 em 02/04/2017 (observação recente arbitrada)\n",
    "if temp[temp[\"store_nbr\"] == 9].loc[\"2017-04-02\"][\"sales\"].max() == 38422.625:\n",
    "    print(\"Atenção: variáveis com presença de outliers!\\n\")\n",
    "else:\n",
    "    print(\"Parabéns, variáveis sem presença de outliers.\\n\")\n",
    "\n",
    "# Modelagem propriamente dita\n",
    "\n",
    "# Variáveis independentes e dependente\n",
    "y = [\"sales\"]\n",
    "x = dados_treino.drop(var_a_remover, axis = 1).columns.values\n",
    "\n",
    "# Criação do modelo de treino\n",
    "tsgen = TimeSeriesSplit(n_splits=5, test_size=12474)\n",
    "\n",
    "preds = []\n",
    "score = []\n",
    "scores_controle = []\n",
    "\n",
    "for treino_ind, val_ind in tsgen.split(dados_treino):\n",
    "    treino_reg = dados_treino.iloc[treino_ind]\n",
    "    validacao_reg = dados_treino.iloc[val_ind]\n",
    "\n",
    "    x_treino = treino_reg[x]\n",
    "    y_treino = treino_reg[y]\n",
    "\n",
    "    x_valid = validacao_reg[x]\n",
    "    y_valid = validacao_reg[y]\n",
    "\n",
    "    reg = xgb.XGBRegressor(base_score = 0.5, booster = \"gbtree\",\n",
    "                           n_estimators = 1500,\n",
    "                           early_stopping_rounds = 100,\n",
    "                           objective = \"reg:squarederror\",\n",
    "                           max_depth = 4,\n",
    "                           learning_rate = 0.01,\n",
    "                           enable_categorical = True, \n",
    "                           device = \"gpu\",\n",
    "                           validate_parameters = True)\n",
    "\n",
    "    \n",
    "    reg.fit(x_treino, y_treino,\n",
    "            eval_set = [(x_treino, y_treino)],\n",
    "#            eval_set = [(x_treino, y_treino), (x_valid, y_valid)], # resolvi desconsiderar a evaluation nos dados de validação, utilizando apenas as informações dos dados de treino\n",
    "            verbose = 200)\n",
    "    \n",
    "    y_pred = reg.predict(x_valid)\n",
    "    preds.append(y_pred)\n",
    "    if (y_pred < 0).sum() > 0:\n",
    "        score = \"negativo\"\n",
    "    else:\n",
    "        score = root_mean_squared_log_error(y_valid, y_pred)\n",
    "    scores_controle.append(score)\n",
    "\n",
    "discard_index = reg.feature_importances_ == 0\n",
    "\n",
    "# Verifica a existência de normalização nos dados\n",
    "if temp[temp.index == \"2017-08-15\"][\"gasolina\"].unique() < 0:\n",
    "    print(\"\\nDADOS COM NORMALIZAÇÃO POR Z-SCORE\")\n",
    "elif temp[temp.index == \"2017-08-15\"][\"gasolina\"].unique() > 5:\n",
    "    print(\"\\nDADOS SEM NORMALIZAÇÃO\")\n",
    "else:\n",
    "    print(\"\\nDADOS COM NORMALIZAÇÃO POR LOG\")\n",
    "\n",
    "# Verifica a existência de variáveis desprezíveis utilizadas na modelagem\n",
    "if discard_index.sum() > 0:\n",
    "    print(\"\\nATENÇÃO! Variáveis sem importância encontradas!\")\n",
    "    print(\"\\nPodem ser descartadas as variáveis: \", dados_treino.drop(var_a_remover, axis = 1).columns.values[discard_index])\n",
    "else: print(\"\\nTodas variáveis utilizadas, nenhuma sem importância.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apresentação e registro em arquivo do modelo utilizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = (\".json\")\n",
    "save = (\"modelo\"+(nome_modelo + ext))\n",
    "reg.save_model(\"./modelos/\"+save)\n",
    "print(\"###### MODELO \" + nome_modelo + \" ######\")\n",
    "print(\"\\nRegistro gerado em \" + datetime.now().strftime(\"%d-%m-%Y\") + \" às \" + datetime.now().strftime(\"%H:%M\") + \".\")\n",
    "print(\"Modelo utilizado salvo como\", save)\n",
    "if temp[temp.index == \"2017-08-15\"][\"gasolina\"].unique() < 0:\n",
    "    print(\"Dados com normalização por ***Z-SCORE***\")\n",
    "elif temp[temp.index == \"2017-08-15\"][\"gasolina\"].unique() > 5:\n",
    "    print(\"Dados ***sem normalização***\")\n",
    "else:\n",
    "    print(\"Dados com normalização por ***LOG***\")\n",
    "print(\"Período de análise entre\", dados_treino.index.min().strftime(\"%d-%m-%Y\"), \"e\", dados_treino.index.max().strftime(\"%d-%m-%Y\"))\n",
    "if temp[temp[\"store_nbr\"] == 9].loc[\"2017-04-02\"][\"sales\"].max() == 38422.625:\n",
    "    print(\"Atenção: análise realizada com outliers presentes nas variáveis!\")\n",
    "else:\n",
    "    print(\"Análise realizada sem presença de outliers nas variáveis.\")\n",
    "print(\"\\nScores obtidos no controle:\", scores_controle)\n",
    "print(\"Média dos scores obtidos no controle:\", pd.DataFrame(scores_controle).mean(numeric_only= True).values)\n",
    "print(\"Mediana dos scores obtidos no controle:\", pd.DataFrame(scores_controle).median(numeric_only= True).values)\n",
    "print(\"Melhor score obtido no controle:\", pd.DataFrame(scores_controle).min(numeric_only= True).values)\n",
    "print(\"\\nFeatures utilizadas no modelo e suas respectivas importâncias:\")\n",
    "importancias = pd.DataFrame(reg.feature_importances_, reg.feature_names_in_)\n",
    "importancias.reset_index(inplace = True)\n",
    "importancias.columns = [\"variável\", \"importância\"]\n",
    "print(importancias.sort_values(by = \"importância\", ascending = False))\n",
    "if discard_index.sum() > 0:\n",
    "    print(\"\\nFeatures sem importância:\", dados_treino.drop(var_a_remover, axis = 1).columns.values[discard_index])\n",
    "else: print(\"\\nNão foram identificadas features sem importância.\")\n",
    "print(\"\\nDataset timeseries split em \" + str(tsgen.n_splits) + \" subconjuntos.\")\n",
    "print(\"Tamanho de teste para cada split: \" + str(tsgen.test_size) + \" observações\")\n",
    "print(\"\\nParâmetros do modelo:\")\n",
    "print(\"           base_score: \" + str(reg.base_score))\n",
    "print(\"              booster: \" + str(reg.booster))\n",
    "print(\"         n_estimators: \" + str(reg.n_estimators))\n",
    "print(\"early_stopping_rounds: \" + str(reg.early_stopping_rounds))\n",
    "print(\"            objective: \" + reg.objective)\n",
    "print(\"            max_depth: \" + str(reg.max_depth))\n",
    "print(\"        learning_rate: \" + str(reg.learning_rate))\n",
    "print(\"   enable_categorical: \" + str(reg.enable_categorical))\n",
    "#print(\"                feval: 'rmsle' (função definida manualmente)\")\n",
    "print(\"               device: \" + reg.device)\n",
    "print(\"  validade_parameters: True\")\n",
    "print(\"\\n=======================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gerando as previsões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Manipulando dados para as previsões...\")\n",
    "dados_teste = temp[temp[\"id\"] >= 3000888].copy()\n",
    "dados_teste = dados_teste.drop(var_a_remover, axis = 1)\n",
    "\n",
    "print(\"Gerando as previsões...\")\n",
    "y_final_pre = reg.predict(dados_teste)\n",
    "\n",
    "# Retorno dos valores normalizados\n",
    "if temp[temp.index == \"2017-08-15\"][\"gasolina\"].unique() < 0:\n",
    "    print(\"Dados originais normalizados por Z-Score, retornando valores à normalidade.\")\n",
    "#    y_final = zscore_scaler.inverse_transform(y_final_pre.reshape(-1, 1))\n",
    "    y_final_pre = pd.DataFrame(y_final_pre)\n",
    "    y_final_pre[\"a\"] = 0\n",
    "    y_final_pre[\"b\"] = 0\n",
    "    y_final_pre[\"c\"] = 0\n",
    "    y_final = pd.DataFrame(zscore_scaler.inverse_transform(y_final_pre))\n",
    "    y_final.drop([1, 2], axis = 1, inplace = True)\n",
    "    y_final = y_final.to_numpy(y_final[0])\n",
    "elif temp[temp.index == \"2017-08-15\"][\"gasolina\"].unique() > 5:\n",
    "    y_final = y_final_pre.copy()\n",
    "else:\n",
    "    print(\"Dados originais normalizados por Log, restituindo à normalidade.\")\n",
    "    y_final = np.expm1(y_final_pre)\n",
    "\n",
    "print(\"\\nVerificando previsões de valores de venda negativos...\")\n",
    "if len(y_final[y_final < 0]) > 0:\n",
    "    print(\"Convertendo valores negativos de venda em zero...\")\n",
    "    # Ajuste das previsões negativas, transformando o valor negativo para zero\n",
    "    negativas = len(y_final[y_final < 0])\n",
    "    y_final[y_final < 0] = 0\n",
    "else:\n",
    "    negativas = 0\n",
    "    print(\"Sem previsões de vendas com valores negativos.\")\n",
    "print(\"\\nPrevisões geradas com sucesso. Procedendo com a análise.\\n\")\n",
    "\n",
    "\n",
    "vendas = round((y_final.sum() / temp_snorm[(temp_snorm[\"date\"] <= \"2017-08-15\") & (temp_snorm[\"date\"] >= \"2017-08-01\")][\"sales\"].sum())*100, 2)\n",
    "perda = 100 - vendas\n",
    "\n",
    "print(\"*****\")\n",
    "print(\"Percentual de preenchimento de vendas:\", vendas,\"% dos últimos 15 dias do dataset de treino (01/08/2017 a 15/08/2017)\")\n",
    "print(\"Total estimado de vendas futuras foi de\", round(y_final.sum(), 2))\n",
    "print(\"Valor de venda acumulado dos últimos 15 dias do dataset de treino:\", round(temp_snorm[(temp_snorm[\"date\"] <= \"2017-08-15\") & (temp_snorm[\"date\"] >= \"2017-08-01\")][\"sales\"].sum(), 2))\n",
    "if perda < 0:\n",
    "    print(\"Isso é o equivalente a um ganho teórico de\",abs(perda), \"% de faturamento.\\n\")\n",
    "else: print(\"Isso é o equivalente a uma perda teórica de\",round(perda, 2), \"% de faturamento.\")\n",
    "print(\"*****\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Análise das previsões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Valor mínimo das vendas previstas: \" + str(pd.DataFrame(y_final).min().values))\n",
    "print(\"Valor da mediana das vendas previstas: \" + str(pd.DataFrame(y_final).median().values))\n",
    "print(\"Valor máximo das vendas previstas: \" + str(pd.DataFrame(y_final).max().values))\n",
    "if negativas == 0:\n",
    "    print(\"Sem registro de previsões negativas através deste modelo\")\n",
    "else:\n",
    "    print(\"Quantidade de previsões negativas (tranformadas para zero): \" + str(negativas) + \" (\" + str(round((negativas/len(y_final))*100, 2)) + \"% do total)\")\n",
    "print(\"\\nRelação das frequências dos valores previstos:\")\n",
    "print(\"     -=+ valores mais frequentes +=-\")\n",
    "print(pd.DataFrame(y_final).value_counts().head(10))\n",
    "print(\"     -=+ valores com menor frequência +=-\")\n",
    "print(pd.DataFrame(y_final).value_counts().tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registro em texto do modelo e salvamento dos resultados para submissão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"registros.txt\", \"a\") as registros:\n",
    "    registros.write(\"################ INÍCIO DE REGISTRO - MODELO \" + nome_modelo + \" ################\\n\")\n",
    "    registros.write(\"\\nRegistro gerado em \" + datetime.now().strftime(\"%d-%m-%Y\") + \" às \" + datetime.now().strftime(\"%H:%M\") + \".\")\n",
    "    registros.write(\"\\nModelo utilizado salvo como '\" + save)\n",
    "    if temp[temp.index == \"2017-08-15\"][\"gasolina\"].unique() < 0:\n",
    "        registros.write(\"\\nDados com normalização por ***Z-SCORE***\")\n",
    "    elif temp[temp.index == \"2017-08-15\"][\"gasolina\"].unique() > 5:\n",
    "        registros.write(\"\\nDados ***sem normalização***\")\n",
    "    else:\n",
    "        registros.write(\"\\nDados com normalização por ***LOG***\")\n",
    "    registros.write(\"\\nPeríodo de análise entre \" + str(dados_treino.index.min().strftime(\"%d-%m-%Y\")) + \" e \" + str(dados_treino.index.max().strftime(\"%d-%m-%Y\")) + \". \\n\")\n",
    "    if temp[temp[\"store_nbr\"] == 9].loc[\"2017-04-02\"][\"sales\"].max() == 38422.625:\n",
    "        registros.write(\"Atenção: análise realizada com outliers presentes nas variáveis!\\n\")\n",
    "    else:\n",
    "        registros.write(\"Análise realizada sem presença de outliers nas variáveis.\\n\")\n",
    "    registros.write(\"\\nScores obtidos no controle: \" + str(scores_controle))\n",
    "    if \"negativo\" in scores_controle:\n",
    "        registros.write(\"\\nControle possui score(s) negativo(s), sem média.\")\n",
    "        registros.write(\"\\nControle possui score(s) negativo(s), sem mediana.\")\n",
    "        registros.write(\"\\nControle possui score(s) negativo(s), sem registro de melhor score.\\n\")\n",
    "    else:\n",
    "        registros.write(\"\\nMédia dos scores obtidos no controle:\" + str(pd.DataFrame(scores_controle).mean().values))\n",
    "        registros.write(\"\\nMediana dos scores obtidos no controle:\" + str(pd.DataFrame(scores_controle).median().values))\n",
    "        registros.write(\"\\nMelhor score obtido no controle:\" + str(pd.DataFrame(scores_controle).min().values) + \"\\n\")\n",
    "    registros.write(\"\\nFeatures utilizadas no modelo e seus respectivos impactos:\\n\")\n",
    "    importancias = pd.DataFrame(reg.feature_importances_, reg.feature_names_in_)\n",
    "    importancias.reset_index(inplace = True)\n",
    "    importancias.columns = [\"variável\", \"importância\"]\n",
    "    importancias = importancias.sort_values(by = \"importância\", ascending = False)\n",
    "    registros.write(importancias.to_string(index = False) + \"\\n\")\n",
    "    if discard_index.sum() > 0:\n",
    "        registros.write(\"\\nFeatures sem importância: \"+ str(dados_treino.drop(var_a_remover, axis = 1).columns.values[discard_index]) + \"\\n\")\n",
    "    else: registros.write(\"\\nNão foram identificadas features sem importância. \\n\")\n",
    "    registros.write(\"\\nDataset timeseries split em \" + str(tsgen.n_splits) + \" subconjuntos.\")\n",
    "    registros.write(\"\\nTamanho de teste para cada split: \" + str(tsgen.test_size) + \" observações (dias?)\\n\")\n",
    "    registros.write(\"\\nParâmetros do modelo:\\n\")\n",
    "    registros.write(\"           base_score: \" + str(reg.base_score) + \"\\n\")\n",
    "    registros.write(\"              booster: \" + str(reg.booster) + \"\\n\")\n",
    "    registros.write(\"         n_estimators: \" + str(reg.n_estimators) + \"\\n\")\n",
    "    registros.write(\"early_stopping_rounds: \" + str(reg.early_stopping_rounds) + \"\\n\")\n",
    "    registros.write(\"            objective: \" + reg.objective+ \"\\n\")\n",
    "    registros.write(\"            max_depth: \" + str(reg.max_depth) + \"\\n\")\n",
    "    registros.write(\"        learning_rate: \" + str(reg.learning_rate) + \"\\n\")\n",
    "    registros.write(\"   enable_categorical: \" + str(reg.enable_categorical) + \"\\n\")\n",
    "    registros.write(\"               device: \" + reg.device + \"\\n\")\n",
    "    registros.write(\"  validade_parameters: True\" + \"\\n\")\n",
    "    registros.write(\"\\n\")\n",
    "    registros.write(\" ---===+++ ANÁLISE DAS PREVISÕES REALIZADAS PELO MODELO +++===---\\n\")\n",
    "    registros.write(\"\\n\")\n",
    "    registros.write(\"Valor mínimo das vendas previstas:\" + str(pd.DataFrame(y_final).min().values) + \"\\n\")\n",
    "    registros.write(\"Valor da mediana das vendas previstas:\" + str(pd.DataFrame(y_final).median().values) + \"\\n\")\n",
    "    registros.write(\"Valor máximo das vendas previstas:\" + str(pd.DataFrame(y_final).max().values) + \"\\n\")\n",
    "    if negativas == 0:\n",
    "        registros.write(\"Sem registro de previsões negativas através deste modelo.\\n\")\n",
    "    else:\n",
    "        registros.write(\"Quantidade de previsões negativas (tranformadas para zero): \" + str(negativas) + \" (\" + str(round((negativas/len(y_final))*100, 2)) + \"% do total).\\n\")\n",
    "\n",
    "    registros.write(\"\\nRelação das frequências dos valores previstos:\\n\")\n",
    "    registros.write(\"     -=+ valores mais frequentes +=-\\n\")\n",
    "    maisfreq = pd.DataFrame(y_final).value_counts().head(10)\n",
    "    registros.write(maisfreq.to_string() + \"\\n\")\n",
    "    registros.write(\"     -=+ valores com menor frequência +=-\\n\")\n",
    "    menosfreq = (pd.DataFrame(y_final).value_counts().tail(10))\n",
    "    registros.write(menosfreq.to_string() + \"\\n\")\n",
    "    registros.write(\"\\n################ FINAL DE REGISTRO - MODELO \" + nome_modelo + \" ################\\n\")\n",
    "    registros.write(\"\\n\")\n",
    "    registros.write(\"\\n\")\n",
    "\n",
    "ext_final = (\".csv\")\n",
    "save_final = (\"resultado\"+(nome_modelo + ext_final))\n",
    "submissao = pd.read_csv(\"./csv/sample_submission.csv\")\n",
    "submissao[\"sales\"] = y_final\n",
    "resultado = submissao[[\"id\", \"sales\"]]\n",
    "resultado.to_csv(\"./resultados/\"+save_final, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
